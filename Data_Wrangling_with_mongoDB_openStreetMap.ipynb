{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onclick=\"$('.input, .prompt, .output_stderr, .output_error').toggle();\">Toggle Code</button>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_html\n",
    "display_html(\"\"\"<button onclick=\"$('.input, .prompt, .output_stderr, .output_error').toggle();\">Toggle Code</button>\"\"\", raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# OpenStreetMap\n",
    "***Data Wrangling with mongoDB by NK Zhehua Zou***\n",
    "  \n",
    "Map Area: San Jose, CA, United States  \n",
    "https://mapzen.com/data/metro-extracts/metro/san-jose_california/  \n",
    "  \n",
    "***Table of Contents***\n",
    "1. Data Audit\n",
    "2. Problems Encountered in the Map  \n",
    "Abbreviated Street Names  \n",
    "Postal Codes  \n",
    "3. Data Overview  \n",
    "4. Additional Ideas  \n",
    "Contributor statistics and gamification suggestion  \n",
    "Additional data exploration using MongoDB  \n",
    "5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load packages and libraries\n",
    "import sys\n",
    "sys.path.append(\"script/\")\n",
    "import xml.etree.cElementTree as ET\n",
    "import re\n",
    "\n",
    "### cleaning ###\n",
    "from collections import defaultdict\n",
    "import string\n",
    "\n",
    "### osm to json ###\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "import codecs\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "# This data just a sample for code testing\n",
    "# Please read html file if you want to reviewed entire analysis.\n",
    "data = 'data/sanjose.osm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags\n",
    "Parse through the San Jose dataset with ElementTree and count the number of unique element types to get an overall understanding of the data by using count_tags function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bounds': 1,\n",
       " 'member': 14382,\n",
       " 'nd': 1508760,\n",
       " 'node': 1291540,\n",
       " 'osm': 1,\n",
       " 'relation': 1363,\n",
       " 'tag': 693140,\n",
       " 'way': 171911}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse through the data with ElementTree\n",
    "def count_tags(data):\n",
    "    tags={}\n",
    "    for event, elem in ET.iterparse(data):\n",
    "        if elem.tag in tags:\n",
    "            tags[elem.tag]+=1\n",
    "        else:\n",
    "            tags[elem.tag]=1\n",
    "    return tags\n",
    "\n",
    "count_tags(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keys Type\n",
    "*** For the follinwg function: key_type & process_key. We check the \"k\" value for each. ***  \n",
    "\"lower\", for tags that contain only lowercase letters and are valid.  \n",
    "\"lower_colon\", for otherwise valid tags with a colon in their names.  \n",
    "\"problemchars\", for tags with problematic characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lower': 378290, 'lower_colon': 291114, 'other': 23736, 'problemchars': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of each of three tag categories in a dictionary with re\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "# This regex represents invalid MongoDB characters for keys.\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == 'tag':\n",
    "        if re.match(lower,element.get('k'))!=None:\n",
    "            keys['lower']+=1\n",
    "        elif re.match(lower_colon,element.get('k'))!=None:\n",
    "            keys['lower_colon']+=1\n",
    "        elif re.match(problemchars,element.get('k'))!=None:\n",
    "            keys['problemchars']+=1\n",
    "        else:\n",
    "            keys['other']+=1\n",
    "    return keys\n",
    "\n",
    "def process_key(data):\n",
    "    keys = {'lower': 0, 'lower_colon': 0, 'problemchars': 0, 'other': 0}\n",
    "    for _, element in ET.iterparse(data):\n",
    "        keys = key_type(element, keys)\n",
    "    return keys\n",
    "\n",
    "process_key(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1265 peoples invovlved in the map editing.\n"
     ]
    }
   ],
   "source": [
    "# get users info with ElementTree\n",
    "def process_people(data):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(data):\n",
    "        for e in element:\n",
    "            if 'uid' in e.attrib:\n",
    "                users.add(e.attrib['uid'])\n",
    "    return users\n",
    "\n",
    "number_contributors = len(process_people(data))\n",
    "\n",
    "print str(number_contributors) + ' peoples invovlved in the map editing.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Problems Encountered in the Map\n",
    "After initially downloading a small sample size of the San Jose area and running it, I noticed two main problems with the data, which I will discuss in the following order:  \n",
    "1) Abbreviated street names ('Branham Ln')  \n",
    "2) Inconsistent postal codes ('CA950543', '95014-1899')  \n",
    "3) We use two scripts (street.py & zipcode.py) in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abbreviated Street Names\n",
    "Once the data was imported to MongoDB, some basic querying revealed street name abbreviations. I updated all substrings in problematic address strings, such that 'Branham Ln' becomes 'Branham Lane'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) The main problem we encountered in this dataset come from the street name abbreviation inconsistency. We build the regex matching the last element in the string, where usually the street type is based. Then we come up with a list of mapping that need not to be cleaned.  \n",
    "2) audit_street_type function search the input string for the regex. If there is a match and it is not within the 'expected' list, add the match as a key and add the string to the set.  \n",
    "3) is_street_name function looks at the attribute k if k='addre:street'.  \n",
    "4) audit functio will return the list that match previous two functions.  \n",
    "5) After that, we would do a pretty print the output of the audit. With the list of all the abbreviated street types we can understand and fill-up our 'mapping' dictionary as a preparatio to convert these street name into proper form.  \n",
    "6) update_name is the last step of the process, which take the old name and update them with a better name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zip Codes\n",
    "Postal code strings posed a different sort of problem, forcing a decision to strip all leading and trailing characters before and after the main 5-digit zip code. This effectually dropped all leading state characters (as in 'CA950543') and 4-digit zip code extensions following a hyphen ('95014-1899'). This 5-digit constriction benefits MongoDB aggregation calls on postal codes.  \n",
    "1) Although most of the zip code is correct, there're still a lot of zip code with incorrect 5 digit formats. We will process it like update street name.  \n",
    "2 )The output of the clean zip code are the format of 5 digits or string 'None'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Overview\n",
    "This section contains basic statistics about the dataset and the MongoDB queries used to gather them.  \n",
    "We from street import is_street_name, update_street, mapping_street, mapping_abbrev to cleaning street name  \n",
    "We from zipcode import is_zipcode, update_zipcode to cleaning zipcode  \n",
    "we use shape_elemnt function to wrangle data and parse it.  \n",
    "We use process_map to write json and output to mongoDB. \n",
    "  \n",
    "### Preparing for MongoDB by converting XML to JSON\n",
    "In order to transform the data from XML to JSON, we need to follow these rules:  \n",
    "1) Process only 2 types of top level tags: \"node\" and \"way\"  \n",
    "2) All attributes of \"node\" and \"way\" should be turned into regular key/value pairs, except:   attributes in the CREATED array should be added under a key \"created\", attributes for latitude and longitude should be added to a \"pos\" array, for use in geospacial indexing. Make sure the values inside \"pos\" array are floats and not strings.  \n",
    "3) If second level tag \"k\" value contains problematic characters, it should be ignored  \n",
    "4) If second level tag \"k\" value starts with \"addr:\", it should be added to a dictionary \"address\"  \n",
    "5) If second level tag \"k\" value does not start with \"addr:\", but contains \":\", you can process it same as any other tag.  \n",
    "6) If there is a second \":\" that separates the type/direction of a street, the tag should be ignored  \n",
    "After all the cleaning and data transformation are done, we would use last function process_map and convert the file from XML into JSON format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db=client.project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original OSM file is 286.056458 MB\n"
     ]
    }
   ],
   "source": [
    "print 'The original OSM file is ' + str(os.path.getsize(data)/1.0e6) + ' MB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The JSON file is 327.883245 MB\n"
     ]
    }
   ],
   "source": [
    "print 'The JSON file is ' + str(os.path.getsize(data + '.json')/1.0e6) + ' MB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of documents is 1463451\n"
     ]
    }
   ],
   "source": [
    "# Number of documents, we defined it for next section.\n",
    "number_document = db.doc.find().count()\n",
    "print 'The number of documents is ' + str(number_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of node is 1291532\n"
     ]
    }
   ],
   "source": [
    "# Number of nodes\n",
    "print 'The number of node is ' + str(db.doc.find({'type':'node'}).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of way is 171880\n"
     ]
    }
   ],
   "source": [
    "# Number of ways\n",
    "print 'The number of way is ' + str(db.doc.find({'type':'way'}).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique users is 1257\n"
     ]
    }
   ],
   "source": [
    "# Number of unique users, we defined it for next section.\n",
    "number_unique_users = len(db.doc.distinct('created.user'))\n",
    "print 'The number of unique users is ' + str(number_unique_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first contributor is nmixter with 288570 contributions.\n"
     ]
    }
   ],
   "source": [
    "# Top 1 contributing user\n",
    "cursor = db.doc.aggregate([{'$group':{'_id':'$created.user', 'count':{'$sum':1}}}, {'$sort':{'count':-1}}, {'$limit':1}])\n",
    "for res in cursor:\n",
    "    user1=res['_id']\n",
    "    user1_count=res['count']\n",
    "print 'The first contributor is ' + user1 + ' with '+ str(user1_count) + ' contributions.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 272 users appearing only once.\n"
     ]
    }
   ],
   "source": [
    "# Number of users appearing only once (having 1 post), we defined it for next section.\n",
    "user_once=db.doc.aggregate([{'$group':{'_id':'$created.user', 'count':{'$sum':1}}}, \n",
    "                       {'$sort':{'count':1}},\n",
    "                       {'$match':{'count':1}},\n",
    "                       {'$group':{'_id':'null','total':{'$sum':'$count'}}}\n",
    "                        ])\n",
    "for res in user_once:\n",
    "    number_user_once=res['total']\n",
    "\n",
    "print 'There is ' + str(number_user_once) + ' users appearing only once.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Additional Ideas\n",
    "### Contributor statistics and suggestion\n",
    "According to these results below, we found unbelievable truth.  \n",
    "1) Best contributor gave 19% documents, almost 1/5 of total contributions.  \n",
    "2) Four contributors also over 40% total contributions, it means top 2, top 3 and top 4 contributors are far behind top 1 contributors.  \n",
    "3) Just 100 contributors already gave 95% of total documents, it means rest of people almost have not any contributors in here even if still have 21% contributors gave one post.  \n",
    "4) Every contributor shall gave 1164 documents by average contribution, but most of people can't close to this number.  \n",
    "5) What incentives should we increase? Perhaps we can refer to the experience of waze, which is a great application for navigation app. We can be divided different levels according to contribution, each level users will enjoy different privileges, badges and rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topn_contrib(n, user=False):\n",
    "    if user==True:\n",
    "        topuser=db.doc.aggregate([{'$group':{'_id':'$created.user', 'count':{'$sum':1}}}, \n",
    "                                 {'$sort':{'count':-1}}, {'$limit':n}\n",
    "                                 ])\n",
    "        top_n_users=[]\n",
    "        for res in topuser:\n",
    "            top_n_users.append(res['_id'])\n",
    "\n",
    "    top_n_contrib=db.doc.aggregate([{'$group':{'_id':'$created.user', 'count':{'$sum':1}}}, \n",
    "                         {'$sort':{'count':-1}}, {'$limit':n},\n",
    "                         {'$group':{'_id':'$created.user','total':{'$sum':'$count'}}}\n",
    "                        ])\n",
    "\n",
    "    for res in top_n_contrib:\n",
    "        top_n_contrib_count=res['total']\n",
    "\n",
    "    percent_contrib_topn=(top_n_contrib_count*100)/number_document\n",
    "    \n",
    "    if user==True:\n",
    "        return top_n_users,percent_contrib_topn\n",
    "    else:\n",
    "        return percent_contrib_topn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top1 Contributor is [u'nmixter'], contribution percentage is 19%.\n"
     ]
    }
   ],
   "source": [
    "top1,top1_percent_contrib=topn_contrib(1,user=True)\n",
    "print 'Top1 Contributor is ' + str(top1) + ', contribution percentage is ' + str(top1_percent_contrib) + '%.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These contributors: [u'nmixter', u'mk408', u'Bike Mapper', u'samely'] have 41% contribution rate in this area.\n"
     ]
    }
   ],
   "source": [
    "top4,top4_percent_contrib=topn_contrib(4,user=True)\n",
    "print 'These contributors: ' + str(top4) + ' have ' + str(top4_percent_contrib) + '% contribution rate in this area.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contribution percentage from top 100 users is 95%.\n"
     ]
    }
   ],
   "source": [
    "top100,top100_percent_contrib=topn_contrib(100, user=True)\n",
    "print 'Contribution percentage from top 100 users is ' + str(top100_percent_contrib) + '%.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21% of users contribute with one post.\n"
     ]
    }
   ],
   "source": [
    "percent_user_1post=(number_user_once*100)/number_unique_users\n",
    "print str(percent_user_1post) + '% of users contribute with one post.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of documents per contributor is 1164\n"
     ]
    }
   ],
   "source": [
    "average = number_document/number_unique_users\n",
    "print 'Average number of documents per contributor is ' + str(average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional data exploration using MongoDB queries\n",
    "1) 1463451 people living in this area.  \n",
    "2) We found most amenities are Parking and restaurant, it make sence for a Metropolitan area.  \n",
    "3) I am not suprise to many city bus stations in this Metropolitan area.  \n",
    "4) Shell, 76, Valeroand Chevron have most gas stations in this area, no much suprised for this result, They are every where in Bay Area.  \n",
    "5) Pizza My Heart is the most popular restaurant in this area, they have 9 restaurants in here. I have been there before, their pizza really taste good, but I still have a bit suprise to this result, I though Thaifood is most popular food in San Jose.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'count': 1463451, u'_id': u'population'}]\n"
     ]
    }
   ],
   "source": [
    "population = db.doc.aggregate([{'$group':{'_id':'population', 'count':{'$sum':1}}},\n",
    "                    {'$sort':{'count':-1}}, {'$limit':10}])\n",
    "\n",
    "print list(population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 1835, u'_id': u'parking'}\n",
      "{u'count': 937, u'_id': u'restaurant'}\n",
      "{u'count': 532, u'_id': u'school'}\n",
      "{u'count': 477, u'_id': u'fast_food'}\n",
      "{u'count': 343, u'_id': u'place_of_worship'}\n",
      "{u'count': 238, u'_id': u'cafe'}\n",
      "{u'count': 233, u'_id': u'fuel'}\n",
      "{u'count': 201, u'_id': u'bench'}\n",
      "{u'count': 183, u'_id': u'toilets'}\n",
      "{u'count': 182, u'_id': u'bicycle_parking'}\n"
     ]
    }
   ],
   "source": [
    "# Let's check the number of amenity first\n",
    "amenity = db.doc.aggregate([{'$match':{'amenity':{'$exists':1}}},\n",
    "                               {'$group':{'_id':'$amenity', 'count':{'$sum':1}}},\n",
    "                               {'$sort':{'count':-1}}, {'$limit':10}])\n",
    "for doc in amenity:\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 2, u'_id': None}\n",
      "{u'count': 1, u'_id': u'San Jose Diridon Transit Center'}\n",
      "{u'count': 1, u'_id': u'Valley Fair'}\n",
      "{u'count': 1, u'_id': u'VTA Route 22'}\n",
      "{u'count': 1, u'_id': u'VTA Route 55 Stop#62327'}\n",
      "{u'count': 1, u'_id': u'Santa Clara Transit Center'}\n",
      "{u'count': 1, u'_id': u'VTA Route 55 Stop#62391'}\n"
     ]
    }
   ],
   "source": [
    "bus_station = db.doc.aggregate([{'$match':{'amenity':{'$exists':1}, 'amenity':'bus_station'}},\n",
    "                               {'$group':{'_id':'$name', 'count':{'$sum':1}}},\n",
    "                               {'$sort':{'count':-1}}, {'$limit':10}])\n",
    "for doc in bus_station:\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 71, u'_id': None}\n",
      "{u'count': 25, u'_id': u'Shell'}\n",
      "{u'count': 23, u'_id': u'76'}\n",
      "{u'count': 22, u'_id': u'Valero'}\n",
      "{u'count': 20, u'_id': u'Chevron'}\n",
      "{u'count': 14, u'_id': u'Arco'}\n",
      "{u'count': 5, u'_id': u'Rotten Robbie'}\n",
      "{u'count': 2, u'_id': u'Spartan'}\n",
      "{u'count': 2, u'_id': u'Beacon'}\n",
      "{u'count': 2, u'_id': u'Cal Gas'}\n"
     ]
    }
   ],
   "source": [
    "gas_station = db.doc.aggregate([{'$match':{'amenity':{'$exists':1}, 'amenity':'fuel'}},\n",
    "                    {'$group':{'_id':'$name', 'count':{'$sum':1}}},\n",
    "                    {'$sort':{'count':-1}}, {'$limit':10}])\n",
    "\n",
    "for doc in gas_station:\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 20, u'_id': None}\n",
      "{u'count': 9, u'_id': u'Pizza My Heart'}\n",
      "{u'count': 7, u'_id': u\"Denny's\"}\n",
      "{u'count': 6, u'_id': u'Panera Bread'}\n",
      "{u'count': 6, u'_id': u'Round Table Pizza'}\n",
      "{u'count': 6, u'_id': u'Round Table'}\n",
      "{u'count': 5, u'_id': u'Subway'}\n",
      "{u'count': 5, u'_id': u'IHOP'}\n",
      "{u'count': 4, u'_id': u'Outback Steakhouse'}\n",
      "{u'count': 4, u'_id': u'Pizza Hut'}\n"
     ]
    }
   ],
   "source": [
    "restaurant = db.doc.aggregate([{'$match':{'amenity':{'$exists':1}, 'amenity':'restaurant'}}, \n",
    "                    {'$group':{'_id':'$name', 'count':{'$sum':1}}},\n",
    "                    {'$sort':{'count':-1}}, {'$limit':10}])\n",
    "\n",
    "for doc in restaurant:\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Conclusion\n",
    "1) The map about the city of San Jose is relatively clean so I could retrieve some interesting content. But still the data is not entirely clean.  \n",
    "2) The data contains some mistakes or different references for the same feature. So I had to clean the data programmatically for the street and the postal codes.  \n",
    "3) When we audit the data, it was very clear that although there are minor error caused by human input, the dataset is fairly well-cleaned. Considering there're hundreds of contributors for this map, there is a great numbers of human errors in this project. I'd recommend a srtuctured input form so everyone can input the same data format to reduce this error.  \n",
    "4) We can incentivize users by gamify the contribution process, then we can create a recommendation engine to leverage these data (eg. restaurant recommendation, building, etc).  \n",
    "5) OpenStreetMaps is an open source project, there're still a lot of areas left unexplored as people tend to focus on a certain key areas and left other part outdated. This is most difference between OpenStreetMaps and GoogleMap, they allow every one to create or modify data even it will miss many datas."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
