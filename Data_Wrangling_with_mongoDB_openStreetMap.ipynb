{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onclick=\"$('.input, .prompt, .output_stderr, .output_error').toggle();\">Toggle Code</button>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_html\n",
    "display_html(\"\"\"<button onclick=\"$('.input, .prompt, .output_stderr, .output_error').toggle();\">Toggle Code</button>\"\"\", raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# OpenStreetMap\n",
    "***Data Wrangling with mongoDB by NK Zhehua Zou***\n",
    "  \n",
    "Map Area: San Jose, CA, United States  \n",
    "https://mapzen.com/data/metro-extracts/metro/san-jose_california/  \n",
    "  \n",
    "***Table of Contents***\n",
    "1. Data Audit\n",
    "2. Problems Encountered in the Map  \n",
    "Abbreviated Street Names  \n",
    "Postal Codes  \n",
    "3. Data Overview  \n",
    "4. Additional Ideas  \n",
    "Contributor statistics and gamification suggestion  \n",
    "Additional data exploration using MongoDB  \n",
    "5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load packages and libraries\n",
    "import sys\n",
    "sys.path.append(\"script/\")\n",
    "import xml.etree.cElementTree as ET\n",
    "import re\n",
    "\n",
    "### cleaning ###\n",
    "from collections import defaultdict\n",
    "import string\n",
    "\n",
    "### osm to json ###\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "import codecs\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "# This data just a sample for code testing\n",
    "# Please read html file if you want to reviewed entire analysis.\n",
    "data = 'data/sample.osm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags\n",
    "Parse through the San Jose dataset with ElementTree and count the number of unique element types to get an overall understanding of the data by using count_tags function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bounds': 1,\n",
       " 'member': 115,\n",
       " 'nd': 21564,\n",
       " 'node': 13332,\n",
       " 'osm': 1,\n",
       " 'relation': 21,\n",
       " 'tag': 7128,\n",
       " 'way': 3721}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse through the data with ElementTree\n",
    "def count_tags(data):\n",
    "    tags={}\n",
    "    for event, elem in ET.iterparse(data):\n",
    "        if elem.tag in tags:\n",
    "            tags[elem.tag]+=1\n",
    "        else:\n",
    "            tags[elem.tag]=1\n",
    "    return tags\n",
    "\n",
    "count_tags(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keys Type\n",
    "*** For the follinwg function: key_type & process_key. We check the \"k\" value for each. ***  \n",
    "\"lower\", for tags that contain only lowercase letters and are valid.  \n",
    "\"lower_colon\", for otherwise valid tags with a colon in their names.  \n",
    "\"problemchars\", for tags with problematic characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lower': 6751, 'lower_colon': 363, 'other': 14, 'problemchars': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of each of three tag categories in a dictionary with re\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "# This regex represents invalid MongoDB characters for keys.\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == 'tag':\n",
    "        if re.match(lower,element.get('k'))!=None:\n",
    "            keys['lower']+=1\n",
    "        elif re.match(lower_colon,element.get('k'))!=None:\n",
    "            keys['lower_colon']+=1\n",
    "        elif re.match(problemchars,element.get('k'))!=None:\n",
    "            keys['problemchars']+=1\n",
    "        else:\n",
    "            keys['other']+=1\n",
    "    return keys\n",
    "\n",
    "def process_key(data):\n",
    "    keys = {'lower': 0, 'lower_colon': 0, 'problemchars': 0, 'other': 0}\n",
    "    for _, element in ET.iterparse(data):\n",
    "        keys = key_type(element, keys)\n",
    "    return keys\n",
    "\n",
    "process_key(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 peoples invovlved in the map editing.\n"
     ]
    }
   ],
   "source": [
    "# get users info with ElementTree\n",
    "def process_people(data):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(data):\n",
    "        for e in element:\n",
    "            if 'uid' in e.attrib:\n",
    "                users.add(e.attrib['uid'])\n",
    "    return users\n",
    "\n",
    "number_contributors = len(process_people(data))\n",
    "\n",
    "print str(number_contributors) + ' peoples invovlved in the map editing.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Problems Encountered in the Map\n",
    "After initially downloading a small sample size of the San Jose area and running it, I noticed three main problems with the data, which I will discuss in the following order:  \n",
    "1) Abbreviated street names ('Branham Ln')  \n",
    "2) Inconsistent postal codes ('CA950543', '95014-1899')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abbreviated Street Names\n",
    "Once the data was imported to MongoDB, some basic querying revealed street name abbreviations. I updated all substrings in problematic address strings, such that 'Branham Ln' becomes 'Branham Lane'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) The main problem we encountered in this dataset come from the street name abbreviation inconsistency. We build the regex matching the last element in the string, where usually the street type is based. Then we come up with a list of mapping that need not to be cleaned.  \n",
    "2) audit_street_type function search the input string for the regex. If there is a match and it is not within the 'expected' list, add the match as a key and add the string to the set.  \n",
    "3) is_street_name function looks at the attribute k if k='addre:street'.  \n",
    "4) audit functio will return the list that match previous two functions.  \n",
    "5) After that, we would do a pretty print the output of the audit. With the list of all the abbreviated street types we can understand and fill-up our 'mapping' dictionary as a preparatio to convert these street name into proper form.  \n",
    "6) update_name is the last step of the process, which take the old name and update them with a better name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zip Codes\n",
    "Postal code strings posed a different sort of problem, forcing a decision to strip all leading and trailing characters before and after the main 5-digit zip code. This effectually dropped all leading state characters (as in 'CA950543') and 4-digit zip code extensions following a hyphen ('95014-1899'). This 5-digit constriction benefits MongoDB aggregation calls on postal codes.  \n",
    "1) Although most of the zip code is correct, there're still a lot of zip code with incorrect 5 digit formats. We will process it like update street name.  \n",
    "2 )The output of the clean zip code is summarised below. There are the format of 5 digits or string 'None'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Overview\n",
    "This section contains basic statistics about the dataset and the MongoDB queries used to gather them.  \n",
    "  \n",
    "### Preparing for MongoDB by converting XML to JSON\n",
    "In order to transform the data from XML to JSON, we need to follow these rules:  \n",
    "1) Process only 2 types of top level tags: \"node\" and \"way\"  \n",
    "2) All attributes of \"node\" and \"way\" should be turned into regular key/value pairs, except:   attributes in the CREATED array should be added under a key \"created\", attributes for latitude and longitude should be added to a \"pos\" array, for use in geospacial indexing. Make sure the values inside \"pos\" array are floats and not strings.  \n",
    "3) If second level tag \"k\" value contains problematic characters, it should be ignored  \n",
    "4) If second level tag \"k\" value starts with \"addr:\", it should be added to a dictionary \"address\"  \n",
    "5) If second level tag \"k\" value does not start with \"addr:\", but contains \":\", you can process it same as any other tag.  \n",
    "6) If there is a second \":\" that separates the type/direction of a street, the tag should be ignored  \n",
    "After all the cleaning and data transformation are done, we would use last function process_map and convert the file from XML into JSON format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db=client.project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original OSM file is 3.329866 MB\n"
     ]
    }
   ],
   "source": [
    "print 'The original OSM file is ' + str(os.path.getsize(data)/1.0e6) + ' MB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The JSON file is 3.795992 MB\n"
     ]
    }
   ],
   "source": [
    "print 'The JSON file is ' + str(os.path.getsize(data + '.json')/1.0e6) + ' MB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of documents is 17053\n"
     ]
    }
   ],
   "source": [
    "# Number of documents, we defined it for next section.\n",
    "number_document = db.doc.find().count()\n",
    "print 'The number of documents is ' + str(number_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of node is 13332\n"
     ]
    }
   ],
   "source": [
    "# Number of nodes\n",
    "print 'The number of node is ' + str(db.doc.find({'type':'node'}).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of way is 3721\n"
     ]
    }
   ],
   "source": [
    "# Number of ways\n",
    "print 'The number of way is ' + str(db.doc.find({'type':'way'}).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique users is 91\n"
     ]
    }
   ],
   "source": [
    "# Number of unique users, we defined it for next section.\n",
    "number_unique_users = len(db.doc.distinct('created.user'))\n",
    "print 'The number of unique users is ' + str(number_unique_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first contributor is TELCOM IP with 4921 contributions.\n"
     ]
    }
   ],
   "source": [
    "# Top 1 contributing user\n",
    "cursor = db.doc.aggregate([{'$group':{'_id':'$created.user', 'count':{'$sum':1}}}, {'$sort':{'count':-1}}, {'$limit':1}])\n",
    "for res in cursor:\n",
    "    user1=res['_id']\n",
    "    user1_count=res['count']\n",
    "print 'The first contributor is ' + user1 + ' with '+ str(user1_count) + ' contributions.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 22 users appearing only once.\n"
     ]
    }
   ],
   "source": [
    "# Number of users appearing only once (having 1 post), we defined it for next section.\n",
    "user_once=db.doc.aggregate([{'$group':{'_id':'$created.user', 'count':{'$sum':1}}}, \n",
    "                       {'$sort':{'count':1}},\n",
    "                       {'$match':{'count':1}},\n",
    "                       {'$group':{'_id':'null','total':{'$sum':'$count'}}}\n",
    "                        ])\n",
    "for res in user_once:\n",
    "    number_user_once=res['total']\n",
    "\n",
    "print 'There is ' + str(number_user_once) + ' users appearing only once.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Additional Ideas\n",
    "### Contributor statistics and suggestion\n",
    "According to these results below, we found unbelievable truth.  \n",
    "1) Best contributor gave 28% documents, greater than 1/4 of total contributions.  \n",
    "2) Three contributors also over half of total contributions, it means top 2 and top 3 contributors are far behind top 1 contributors.  \n",
    "3) Just 20 contributors already gave 96% of total documents, it means rest of people almost have not any contributors in here even if still have 24% contributors gave one post.  \n",
    "4) Eeery contributor shall gave 187 documents by average contribution, but most of people can't close to this number.  \n",
    "5) What incentives should we increase? Perhaps we can refer to the experience of waze, which is a great application for navigation app. We can be divided different levels according to contribution, each level users will enjoy different privileges, badges and rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topn_contrib(n, user=False):\n",
    "    if user==True:\n",
    "        topuser=db.doc.aggregate([{'$group':{'_id':'$created.user', 'count':{'$sum':1}}}, \n",
    "                                 {'$sort':{'count':-1}}, {'$limit':n}\n",
    "                                 ])\n",
    "        top_n_users=[]\n",
    "        for res in topuser:\n",
    "            top_n_users.append(res['_id'])\n",
    "\n",
    "    top_n_contrib=db.doc.aggregate([{'$group':{'_id':'$created.user', 'count':{'$sum':1}}}, \n",
    "                         {'$sort':{'count':-1}}, {'$limit':n},\n",
    "                         {'$group':{'_id':'$created.user','total':{'$sum':'$count'}}}\n",
    "                        ])\n",
    "\n",
    "    for res in top_n_contrib:\n",
    "        top_n_contrib_count=res['total']\n",
    "\n",
    "    percent_contrib_topn=(top_n_contrib_count*100)/number_document\n",
    "    \n",
    "    if user==True:\n",
    "        return top_n_users,percent_contrib_topn\n",
    "    else:\n",
    "        return percent_contrib_topn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top1 Contributor is [u'TELCOM IP'], contribution percentage is 28%.\n"
     ]
    }
   ],
   "source": [
    "top1,top1_percent_contrib=topn_contrib(1,user=True)\n",
    "print 'Top1 Contributor is ' + str(top1) + ', contribution percentage is ' + str(top1_percent_contrib) + '%.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These contributors: [u'TELCOM IP', u'negro', u'Diego Sanguinetti'] have 55% contribution rate in this area.\n"
     ]
    }
   ],
   "source": [
    "top3,top3_percent_contrib=topn_contrib(3,user=True)\n",
    "print 'These contributors: ' + str(top3) + ' have ' + str(top3_percent_contrib) + '% contribution rate in this area.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contribution percentage from top 20 users is 96%.\n"
     ]
    }
   ],
   "source": [
    "top20,top20_percent_contrib=topn_contrib(20, user=True)\n",
    "print 'Contribution percentage from top 20 users is ' + str(top20_percent_contrib) + '%.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24% of users contribute with one post.\n"
     ]
    }
   ],
   "source": [
    "percent_user_1post=(number_user_once*100)/number_unique_users\n",
    "print str(percent_user_1post) + '% of users contribute with one post.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of documents per contributor is 187\n"
     ]
    }
   ],
   "source": [
    "average = number_document/number_unique_users\n",
    "print 'Average number of documents per contributor is ' + str(average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional data exploration using MongoDB queries\n",
    "1) 17053 people living in this area.  \n",
    "2) We found most amenities are bus stations, gas stations (fuel) and schools in this area. Let's explorating them.  \n",
    "3) I am a bit suprised for this result, there has many long distance bus station in this small area. I though there has many caltrain or city bus stations.  \n",
    "4) It looks like Grifo has most gas stations in this area, no much suprised for this result, but I can't belive only 1 Vista and have not some popular gas station like Shell in here.  \n",
    "5) Pescador is the most popular restaurant in this area, they have 2 restaurant in here. After google it, I found this is a fish restaurant and keep a lower rate 3 in 5 stars. Interesting, they don't have delicious food for residents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'count': 17053, u'_id': u'population'}]\n"
     ]
    }
   ],
   "source": [
    "population = db.doc.aggregate([{'$group':{'_id':'population', 'count':{'$sum':1}}},\n",
    "                    {'$sort':{'count':-1}}, {'$limit':10}])\n",
    "\n",
    "print list(population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 22, u'_id': u'bus_station'}\n",
      "{u'count': 12, u'_id': u'fuel'}\n",
      "{u'count': 12, u'_id': u'school'}\n",
      "{u'count': 7, u'_id': u'restaurant'}\n",
      "{u'count': 5, u'_id': u'hospital'}\n",
      "{u'count': 5, u'_id': u'place_of_worship'}\n",
      "{u'count': 4, u'_id': u'townhall'}\n",
      "{u'count': 4, u'_id': u'marketplace'}\n",
      "{u'count': 4, u'_id': u'university'}\n",
      "{u'count': 4, u'_id': u'veterinary'}\n",
      "{u'count': 3, u'_id': u'fire_station'}\n",
      "{u'count': 2, u'_id': u'bank'}\n",
      "{u'count': 2, u'_id': u'bar'}\n",
      "{u'count': 2, u'_id': u'cafe'}\n",
      "{u'count': 1, u'_id': u'doctors'}\n",
      "{u'count': 1, u'_id': u'police'}\n",
      "{u'count': 1, u'_id': u'community_centre'}\n",
      "{u'count': 1, u'_id': u'post_office'}\n",
      "{u'count': 1, u'_id': u'clinic'}\n",
      "{u'count': 1, u'_id': u'public_building'}\n",
      "{u'count': 1, u'_id': u'parking'}\n"
     ]
    }
   ],
   "source": [
    "# Let's check the number of amenity first\n",
    "amenity = db.doc.aggregate([{'$match':{'amenity':{'$exists':1}}},\n",
    "                               {'$group':{'_id':'$amenity', 'count':{'$sum':1}}},\n",
    "                               {'$sort':{'count':-1}}])\n",
    "for doc in amenity:\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 2, u'_id': None}\n",
      "{u'count': 2, u'_id': u'Emtrafesac'}\n",
      "{u'count': 1, u'_id': u'Ku\\xe9lap'}\n",
      "{u'count': 1, u'_id': u'exclusiva'}\n",
      "{u'count': 1, u'_id': u'Emtrafesa'}\n",
      "{u'count': 1, u'_id': u'cruz del sur'}\n",
      "{u'count': 1, u'_id': u'Transportes Chiclayo'}\n",
      "{u'count': 1, u'_id': u'IttsaBus'}\n",
      "{u'count': 1, u'_id': u'Tepsa'}\n",
      "{u'count': 1, u'_id': u'americas express'}\n",
      "{u'count': 1, u'_id': u'Terminal Flores Hermanos'}\n",
      "{u'count': 1, u'_id': u'Transportes Linea'}\n",
      "{u'count': 1, u'_id': u'Oltursa'}\n",
      "{u'count': 1, u'_id': u'Collectivos'}\n",
      "{u'count': 1, u'_id': u'Transportes Acunta'}\n",
      "{u'count': 1, u'_id': u'El Cumbe'}\n",
      "{u'count': 1, u'_id': u'Burga Express'}\n",
      "{u'count': 1, u'_id': u'Terminal Nort - Terminal North'}\n",
      "{u'count': 1, u'_id': u'Transportes JEANBUCA'}\n",
      "{u'count': 1, u'_id': u'Movil Tours'}\n"
     ]
    }
   ],
   "source": [
    "bus_station = db.doc.aggregate([{'$match':{'amenity':{'$exists':1}, 'amenity':'bus_station'}},\n",
    "                               {'$group':{'_id':'$name', 'count':{'$sum':1}}},\n",
    "                               {'$sort':{'count':-1}}])\n",
    "for doc in bus_station:\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 2, u'_id': None}\n",
      "{u'count': 2, u'_id': u'Primax'}\n",
      "{u'count': 1, u'_id': u'Vista Alegre'}\n",
      "{u'count': 1, u'_id': u'Pecsa'}\n",
      "{u'count': 1, u'_id': u'Pesca'}\n",
      "{u'count': 1, u'_id': u'Grifo San Antonio'}\n",
      "{u'count': 1, u'_id': u'Grifos Gran Prix'}\n",
      "{u'count': 1, u'_id': u'Grifo Le\\xf3n de Oro'}\n",
      "{u'count': 1, u'_id': u'Repsol'}\n",
      "{u'count': 1, u'_id': u'Terminal EPSEL'}\n"
     ]
    }
   ],
   "source": [
    "gas_station = db.doc.aggregate([{'$match':{'amenity':{'$exists':1}, 'amenity':'fuel'}},\n",
    "                    {'$group':{'_id':'$name', 'count':{'$sum':1}}},\n",
    "                    {'$sort':{'count':-1}}])\n",
    "\n",
    "for doc in gas_station:\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 2, u'_id': u'El Paladar'}\n",
      "{u'count': 1, u'_id': u'Mi Tia'}\n",
      "{u'count': 1, u'_id': u'D Chota'}\n",
      "{u'count': 1, u'_id': u'GIZA'}\n",
      "{u'count': 1, u'_id': u'Hebron'}\n",
      "{u'count': 1, u'_id': u'El Pescador'}\n"
     ]
    }
   ],
   "source": [
    "restaurant = db.doc.aggregate([{'$match':{'amenity':{'$exists':1}, 'amenity':'restaurant'}}, \n",
    "                    {'$group':{'_id':'$name', 'count':{'$sum':1}}},\n",
    "                    {'$sort':{'count':-1}}, {'$limit':10}])\n",
    "\n",
    "for doc in restaurant:\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Conclusion\n",
    "1) The map about the city of San Jose is relatively clean so I could retrieve some interesting content. But still the data is not entirely clean.  \n",
    "2) The data contains some mistakes or different references for the same feature. So I had to clean the data programmatically for the street and the postal codes.  \n",
    "3) When we audit the data, it was very clear that although there are minor error caused by human input, the dataset is fairly well-cleaned. Considering there're hundreds of contributors for this map, there is a great numbers of human errors in this project. I'd recommend a srtuctured input form so everyone can input the same data format to reduce this error.  \n",
    "4) We can incentivize users by gamify the contribution process, then we can create a recommendation engine to leverage these data (eg. restaurant recommendation, building, etc).  \n",
    "5) OpenStreetMaps is an open source project, there're still a lot of areas left unexplored as people tend to focus on a certain key areas and left other part outdated. Since each node has a coordinate (lattitude & longtitude), we can resolve this issue by cross-referencing/cross-validating missing data from other database like Google API."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
